{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Applications of Regular Expressions\n",
    "\n",
    "Today, we will be focusing on more applications of those tools and hoping to explore the potential of tools that we have covered thus far.\n",
    "\n",
    "### Lesson Outline:\n",
    "- Q&A regarding Thursday's content\n",
    "- Examples (with BK's data)\n",
    "- Practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing different packages\n",
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from nltk import tokenize\n",
    "from collections import Counter\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('Grand Strategy of Phillip II Text.txt', 'r',encoding = 'utf-8', errors='ignore') as f:\n",
    "    read_text = f.read()\n",
    "print(read_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's start off by getting a rough list of proper nouns with relative frequencies - this will help us narrow down people, places and their relations\n",
    "# capital 'W' mean NOT word characters (not letters or numbers)\n",
    "pp.pprint(Counter(re.findall('[A-Z]\\w+',read_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# making a table out of the above dictionary\n",
    "names_table = Table(['Name', 'Count'])\n",
    "names = Counter(re.findall('[A-Z]\\w+',read_text))\n",
    "for name in names.keys():\n",
    "    row = [name, names[name]]\n",
    "    names_table.append(row)\n",
    "names_table.sort('Count', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the number of unique names in the work\n",
    "len(names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many times those unique names appear in total\n",
    "sum(names_table.column('Count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# making a histogram of the counts distribution\n",
    "# most of the names only appear very few times\n",
    "names_table.hist('Count', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# while we're at it, let's get a list of all the years that appear in the text along with relative frequencies\n",
    "pp.pprint(Counter(re.findall('\\d{4}',read_text))) #why did I have 4 within my input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let's put these two together in a very simple way. First, let's search for statements that explained events \n",
    "#in the most frequently mentioned years\n",
    "info_1588 = re.findall('[\\S\\s]{,45}15[7-8][0-9][\\S\\s]{,45}', read_text)\n",
    "info_1588_parsed = []\n",
    "for elem in info_1588:\n",
    "    if 'Philip' in elem:\n",
    "        info_1588_parsed.append(elem)\n",
    "info_1588_parsed\n",
    "#this query is not perfect. What are ways that you would improve it? Try them out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#let's try the same thing again, but now with a frequently mentioned country\n",
    "info_england = re.findall('[\\S\\s]{,45}England[\\S\\s]{,45}', read_text)\n",
    "info_england_parsed = []\n",
    "for elem in info_england:\n",
    "    if 'Philip' in elem:\n",
    "        info_england_parsed.append(elem)\n",
    "info_england_parsed\n",
    "#What are ways that you could improve this query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_words = [re.findall('[A-Z][a-z]+',elem) + re.findall('\\d{4}', elem) for elem in info_england_parsed if re.search('[A-Z][a-z]+', elem)]\n",
    "date_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_date_dict = {}\n",
    "for x in range(1500,1600):\n",
    "    for elem in date_words:\n",
    "        if str(x) in elem:\n",
    "            word_date_dict[str(x)] = elem\n",
    "word_date_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Position\n",
    "\n",
    "We are now going to look at where select characters appear within the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# our select characters, who we will compare to Philip\n",
    "characters = ['Elizabeth', 'Estado', 'God']\n",
    "\n",
    "# getting the starting positions for each occurrence of each character\n",
    "philip_positions = np.array([wrd.start() for wrd in re.finditer('Philip', read_text)])\n",
    "\n",
    "# putting the positions of our select characters in a dictionary\n",
    "# so that we can easily access them later\n",
    "character_positions = {}\n",
    "for character in characters:\n",
    "    positions = np.array([wrd.start() for wrd in re.finditer(character, read_text)])\n",
    "    character_positions[character] = positions  \n",
    "\n",
    "\n",
    "# printing out the occurrences of each character's name\n",
    "for char in characters:\n",
    "    print(char + ': ' + str(len(character_positions[char])) + ' occurrences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the positions of where each of these mentions comes up. We will start with Philip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the figure\n",
    "width = 15\n",
    "height = 2.5\n",
    "fig = plt.figure(figsize=(width, height))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(0,len(read_text))\n",
    "ax.set_ylim(0,10)\n",
    "plt.title('Philip')\n",
    "\n",
    "# drawing the horizontal line\n",
    "xmin = 0\n",
    "xmax = len(read_text)\n",
    "y = 5\n",
    "plt.hlines(y, xmin, xmax)\n",
    "\n",
    "# plotting each point\n",
    "for each in philip_positions:\n",
    "    plt.plot(each,y, \"|\", ms = 55, mew=.6)\n",
    "\n",
    "# a e s t h e t i c\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line represents the indices within the string that is our corpus, about 1.5 million characters long. Each line represents the point where a substring, in this case 'Philip,' begins. 'Philip' appears all throughout the book, not even accounting for mentions of 'King' or other pronouns refering to him. Not really a suprising result. Let's look at where our other select characters show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for loop with each character\n",
    "for char in characters:\n",
    "    # set up the figure\n",
    "    width = 15\n",
    "    height = 2.5\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim(0,len(read_text))\n",
    "    ax.set_ylim(0,10)\n",
    "    plt.title(char)\n",
    "\n",
    "    # drawing the horizontal line\n",
    "    xmin = 0\n",
    "    xmax = len(read_text)\n",
    "    y = 5\n",
    "    plt.hlines(y, xmin, xmax)\n",
    "    \n",
    "    # plotting each point\n",
    "    for each in character_positions[char]:\n",
    "        plt.plot(each,y, \"|\", ms = 55,mew=.6)\n",
    "\n",
    "    # a e s t h e t i c\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting patterns that you can see in the appearance of names. Estado occurs in a very select group near the end of the work. God is pretty spread out, but has a dense patch about a quarter way through. Elizabeth doesn't have many mentions until a third of the book has passed, then occurs quite a few times. Pick out some other characters that you want to see this for, insert their name into the list `characters`, then run the cells again to explore some others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How close are characters?\n",
    "\n",
    "We are now going to try to judge how close of a relationship two individuals have. One way to do this is by comparing the position of their letters within the string. For example, if we want to see how related God is to Philip, we can see how far away the closest 'Philip' is to 'God' within our corpus. If we do that for all occurrences of God, we can see, on average, how close Philip is to God. We can then do that for every one of our select individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# performing this operation as a loop so that\n",
    "# we can do this for all select characters\n",
    "boxplot_table = Table(['Character', 'Distance'])\n",
    "for character in character_positions.keys():\n",
    "    \n",
    "    # collecting numbers for a later boxplot\n",
    "    to_add = Table()\n",
    "    distance_collections = []\n",
    "    \n",
    "    # for each position for each occurance of the select character\n",
    "    for position in character_positions[character]:\n",
    "        # computing the absolute distance between that specific occurance of character and all occurances of philip\n",
    "        distances = abs(philip_positions - position)\n",
    "        # finding the smallest of those distances\n",
    "        closest_distance = min(distances)\n",
    "        # adding that distance to the list\n",
    "        distance_collections.append(closest_distance)\n",
    "        \n",
    "    # finding the average of those distances\n",
    "    avg_distance = np.mean(distance_collections)\n",
    "    \n",
    "    # collecting numbers for a later boxplot\n",
    "    to_add = to_add.with_column('Distance', distance_collections).with_column('Character', character)\n",
    "    boxplot_table.append(to_add)\n",
    "    \n",
    "\n",
    "    \n",
    "    print('Philip is on average {} characters away from {}'.format(str(round(avg_distance,2)),character))\n",
    "    print('Median: ' + str(np.median(distance_collections)) + ' characters\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we just looked at the average, put the median is much more telling. The data definitely seems to be skewed by some outliers. The following boxplot helps look at the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "height, width = 14, 19\n",
    "fig = plt.figure(figsize=(width, height))\n",
    "sns.boxplot(x=boxplot_table['Character'], y=boxplot_table['Distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do this is to measure relationships is to see how often the characters appear in sentences together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using the NLTK tokenizer to break the corpus up by sentences\n",
    "broken_up_sentences = tokenize.sent_tokenize(read_text)\n",
    "\n",
    "# initializing dictionary\n",
    "common_sentences = {}\n",
    "\n",
    "for character in characters:\n",
    "    # adding one to a list for each time that philip and character appear in the same sentence\n",
    "    both_appear = [1 for sentence in broken_up_sentences if 'Philip' in sentence and character in sentence]\n",
    "    # summing that to get the number of sentences they appear in together\n",
    "    num_sentences = sum(both_appear)\n",
    "    # adding value to dictionary\n",
    "    common_sentences[character] = num_sentences\n",
    "    # making a string version of num_sentences for printing\n",
    "    str_num = str(num_sentences)\n",
    "    print('Philip and {}: {} sentences with both'.format(character, str_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing you may want to consider is controlling for how often the term appears. For example, Elizabeth is in about the same amount of sentences with Philip as Estado is. But Elizabeth appears 356 times in the work, and Estado only appears 225 times. This might lead us to think that Estado has a much stronger relationship with Philip. Below perform these calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for character in characters:\n",
    "    # total number of times the character's name appears\n",
    "    total_appearances = len(character_positions[character])\n",
    "    # sentences where philip and character appear\n",
    "    appearances_with_philip = common_sentences[character]\n",
    "    # dividing common appearances by the total number of appearances\n",
    "    relative = round(appearances_with_philip / total_appearances, 4)\n",
    "    print('{}: {}'.format(character, relative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at some of the sentences where God and Phillip both appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sentence in broken_up_sentences:\n",
    "    if 'Philip' in sentence and 'God' in sentence:\n",
    "        print(sentence + '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above result, we can see that the sentence tokenizer has a little bit of trouble with the text, but nonetheless, God and Philip are still pretty close in the text for these instances.\n",
    "\n",
    "Once again, if you add some other characters to `characters`, then run through all of the cells again, you'll be able to perform these operations for them.\n",
    "\n",
    "There are many different ways to do this, these are just some basic ones to get you thinking about the potential things that you can do with your text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Bonus</b>: Read about extracting social networks from books\n",
    "http://www1.cs.columbia.edu/~delson/pubs/ACL2010-ElsonDamesMcKeown.pdf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
